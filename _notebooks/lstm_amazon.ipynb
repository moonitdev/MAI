{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faced-fortune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-05-15</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.93</td>\n",
       "      <td>72160000.0</td>\n",
       "      <td>-0.9962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-16</th>\n",
       "      <td>1.73</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.71</td>\n",
       "      <td>14700000.0</td>\n",
       "      <td>-0.1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-19</th>\n",
       "      <td>1.71</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.62</td>\n",
       "      <td>6110000.0</td>\n",
       "      <td>-0.0116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-20</th>\n",
       "      <td>1.64</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.64</td>\n",
       "      <td>5470000.0</td>\n",
       "      <td>-0.0409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-21</th>\n",
       "      <td>1.43</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.37</td>\n",
       "      <td>18850000.0</td>\n",
       "      <td>-0.1280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close  Open  High   Low      Volume  Change\n",
       "Date                                                   \n",
       "1997-05-15   1.96  2.44  2.50  1.93  72160000.0 -0.9962\n",
       "1997-05-16   1.73  1.97  1.98  1.71  14700000.0 -0.1173\n",
       "1997-05-19   1.71  1.76  1.77  1.62   6110000.0 -0.0116\n",
       "1997-05-20   1.64  1.73  1.75  1.64   5470000.0 -0.0409\n",
       "1997-05-21   1.43  1.64  1.65  1.37  18850000.0 -0.1280"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [LSTM RNN을 이용하여 인공지능 주가 예측하기](https://ititit1.tistory.com/61)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import FinanceDataReader as fdr\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 아마존 \n",
    "STOCK_CODE = 'AMZN'\n",
    "stock = fdr.DataReader(STOCK_CODE)\n",
    "stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "certified-anthropology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화\n",
    "def data_standardization(x):\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np - x_np.mean()) / x_np.std()\n",
    " \n",
    "# 너무 작거나 너무 큰 값이 학습을 방해하는 것을 방지하고자 정규화한다\n",
    "# x가 양수라는 가정하에 최소값과 최대값을 이용하여 0~1사이의 값으로 변환\n",
    "# Min-Max scaling\n",
    "def min_max_scaling(x):\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np - x_np.min()) / (x_np.max() - x_np.min() + 1e-7) # 1e-7은 0으로 나누는 오류 예방차원\n",
    " \n",
    "# 정규화된 값을 원래의 값으로 되돌린다\n",
    "# 정규화하기 이전의 org_x값과 되돌리고 싶은 x를 입력하면 역정규화된 값을 리턴한다\n",
    "def reverse_min_max_scaling(org_x, x):\n",
    "    org_x_np = np.asarray(org_x)\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np * (org_x_np.max() - org_x_np.min() + 1e-7)) + org_x_np.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wound-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "input_data_column_cnt = 6  # 입력데이터의 컬럼 개수(Variable 개수)\n",
    "output_data_column_cnt = 1 # 결과데이터의 컬럼 개수\n",
    "\n",
    "seq_length = 28            # 1개 시퀀스의 길이(시계열데이터 입력 개수)\n",
    "rnn_cell_hidden_dim = 20   # 각 셀의 (hidden)출력 크기\n",
    "forget_bias = 1.0          # 망각편향(기본값 1.0)\n",
    "num_stacked_layers = 1     # stacked LSTM layers 개수\n",
    "keep_prob = 1.0            # dropout할 때 keep할 비율\n",
    "\n",
    "epoch_num = 1000           # 에폭 횟수(학습용전체데이터를 몇 회 반복해서 학습할 것인가 입력)\n",
    "learning_rate = 0.01       # 학습률 (적당히 설정해놔야됨 여기서 적당히란...? )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "stuffed-tribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253 entries, 0 to 252\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Date       253 non-null    object\n",
      " 1   Open       253 non-null    object\n",
      " 2   High       253 non-null    object\n",
      " 3   Low        253 non-null    object\n",
      " 4   Close      253 non-null    object\n",
      " 5   Adj Close  253 non-null    object\n",
      " 6   Volume     253 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 14.0+ KB\n",
      "stock_info.shape:  (252, 6)\n",
      "stock_info[0]:  [2.05146997e+03 2.05571997e+03 2.00227002e+03 2.00871997e+03\n",
      " 2.00871997e+03 1.55673000e+07]\n",
      "date 값 삭제 후 rea_dateframe.info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253 entries, 0 to 252\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Open       253 non-null    object\n",
      " 1   High       253 non-null    object\n",
      " 2   Low        253 non-null    object\n",
      " 3   Close      253 non-null    object\n",
      " 4   Adj Close  253 non-null    object\n",
      " 5   Volume     253 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 12.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로딩한다.\n",
    "# stock_file_name = 'TSLAmax.csv' # 주가데이터 파일\n",
    "stock_file_name = './_csv/AMZN.csv'\n",
    "# encoding = 'euc-kr' # 문자 인코딩\n",
    "encoding = 'utf-8'\n",
    "names = ['Date','Open','High','Low','Close','Adj Close','Volume']\n",
    "raw_dataframe = pd.read_csv(stock_file_name, names=names, encoding=encoding) #판다스이용 csv파일 로딩\n",
    "raw_dataframe.info() # 데이터 정보 출력\n",
    "\n",
    "# raw_dataframe.drop('Date', axis=1, inplace=True) # 시간열을 제거하고 dataframe 재생성하지 않기\n",
    "del raw_dataframe['Date'] # 위 줄과 같은 효과\n",
    "\n",
    "stock_info = raw_dataframe.values[1:].astype(np.float) # 금액&거래량 문자열을 부동소수점형으로 변환한다\n",
    "print(\"stock_info.shape: \", stock_info.shape)\n",
    "print(\"stock_info[0]: \", stock_info[0])\n",
    "print('date 값 삭제 후 rea_dateframe.info')\n",
    "raw_dataframe.info() # 데이터 정보 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lesbian-captain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price.shape:  (252, 5)\n",
      "price[0]:  [2051.469971 2055.719971 2002.27002  2008.719971 2008.719971]\n",
      "norm_price[0]:  [0.22086779 0.22307418 0.19532556 0.19867406 0.19867406]\n",
      "====================================================================================================\n",
      "volume.shape:  (252, 1)\n",
      "volume[0]:  [15567300.]\n",
      "norm_volume[0]:  [1.]\n",
      "====================================================================================================\n",
      "x.shape:  (252, 6)\n",
      "x[0]:  [0.22086779 0.22307418 0.19532556 0.19867406 0.19867406 1.        ]\n",
      "x[-1]:  [0.83270343 0.83633229 0.80910802 0.8203476  0.8203476  0.20075237]\n",
      "====================================================================================================\n",
      "y[0]:  [0.19867406]\n",
      "y[-1]:  [0.8203476]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리\n",
    "# 가격과 거래량 수치의 차이가 많아나서 각각 별도로 정규화한다\n",
    "\n",
    "# 가격형태 데이터들을 정규화한다\n",
    "# ['Open','High','Low','Close','Adj Close','Volume']에서 'Adj Close'까지 취함\n",
    "# 곧, 마지막 열 Volume를 제외한 모든 열\n",
    "price = stock_info[:,:-1]\n",
    "norm_price = min_max_scaling(price) # 가격형태 데이터 정규화 처리\n",
    "print(\"price.shape: \", price.shape)\n",
    "print(\"price[0]: \", price[0])\n",
    "print(\"norm_price[0]: \", norm_price[0])\n",
    "print(\"=\"*100) # 화면상 구분용\n",
    "\n",
    "# 거래량형태 데이터를 정규화한다\n",
    "# ['Open','High','Low','Close','Adj Close','Volume']에서 마지막 'Volume'만 취함\n",
    "# [:,-1]이 아닌 [:,-1:]이므로 주의하자! 스칼라가아닌 벡터값 산출해야만 쉽게 병합 가능\n",
    "volume = stock_info[:,-1:]\n",
    "norm_volume = min_max_scaling(volume) # 거래량형태 데이터 정규화 처리\n",
    "print(\"volume.shape: \", volume.shape)\n",
    "print(\"volume[0]: \", volume[0])\n",
    "print(\"norm_volume[0]: \", norm_volume[0])\n",
    "print(\"=\"*100) # 화면상 구분용\n",
    "\n",
    "# 행은 그대로 두고 열을 우측에 붙여 합친다\n",
    "x = np.concatenate((norm_price, norm_volume), axis=1) # axis=1, 세로로 합친다\n",
    "print(\"x.shape: \", x.shape)\n",
    "print(\"x[0]: \", x[0])    # x의 첫 값\n",
    "print(\"x[-1]: \", x[-1])  # x의 마지막 값\n",
    "print(\"=\"*100) # 화면상 구분용\n",
    "\n",
    "y = x[:, [-2]] # 타켓은 주식 종가이다\n",
    "print(\"y[0]: \",y[0])     # y의 첫 값\n",
    "print(\"y[-1]: \",y[-1])   # y의 마지막 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "further-palace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22086779 0.22307418 0.19532556 0.19867406 0.19867406 1.        ]\n",
      " [0.19965007 0.21932592 0.19427686 0.19632748 0.19632748 0.31506015]\n",
      " [0.20965932 0.22519236 0.20212643 0.21993329 0.21993329 0.2718591 ]\n",
      " [0.23101722 0.23101722 0.21075992 0.21484564 0.21484564 0.20717089]\n",
      " [0.21544268 0.22337533 0.20702206 0.22022404 0.22022404 0.1226391 ]\n",
      " [0.21594624 0.24529909 0.21392673 0.23530542 0.23530542 0.25811525]\n",
      " [0.23828015 0.26454407 0.23825417 0.26366661 0.26366661 0.25534523]\n",
      " [0.27248699 0.29068327 0.26475168 0.27243515 0.27243515 0.30421384]\n",
      " [0.27887257 0.28772413 0.27476613 0.27721131 0.27721131 0.13335789]\n",
      " [0.26941885 0.28254821 0.26786659 0.27195237 0.27195237 0.1119274 ]\n",
      " [0.27496855 0.27671295 0.259503   0.2641651  0.2641651  0.08177593]\n",
      " [0.25905141 0.2803626  0.25857902 0.27496335 0.27496335 0.10582059]\n",
      " [0.28126072 0.29024207 0.27779283 0.28251703 0.28251703 0.07858793]\n",
      " [0.28399666 0.28592789 0.26031291 0.27362922 0.27362922 0.11897644]\n",
      " [0.26794441 0.26919045 0.23983241 0.24397003 0.24397003 0.22630602]\n",
      " [0.195798   0.21454975 0.18790167 0.19897001 0.19897001 0.36096037]\n",
      " [0.20786308 0.2121097  0.17256078 0.179995   0.179995   0.33773042]\n",
      " [0.17871791 0.20176305 0.17361461 0.18355117 0.18355117 0.26727546]\n",
      " [0.16008035 0.18116829 0.13328176 0.13408127 0.13408127 0.47409921]\n",
      " [0.09791196 0.13691582 0.09609493 0.13379571 0.13379571 0.56972526]\n",
      " [0.14560121 0.17053088 0.12665738 0.17024012 0.17024012 0.37617071]\n",
      " [0.18136037 0.19224176 0.13604881 0.14689909 0.14689909 0.43091942]\n",
      " [0.16640878 0.18272574 0.15365326 0.18159916 0.18159916 0.23527495]\n",
      " [0.15936392 0.17375479 0.14742344 0.15470715 0.15470715 0.23352509]\n",
      " [0.12925314 0.1478751  0.1263978  0.14279778 0.14279778 0.27074684]\n",
      " [0.07674614 0.12290392 0.07022044 0.09063345 0.09063345 0.45066381]\n",
      " [0.12711423 0.1392572  0.09974978 0.13798524 0.13798524 0.40249656]\n",
      " [0.12034967 0.12734263 0.0910955  0.10114627 0.10114627 0.29562747]] -> [0.02625866]\n"
     ]
    }
   ],
   "source": [
    "dataX = [] # 입력으로 사용될 Sequence Data\n",
    "dataY = [] # 출력(타켓)으로 사용\n",
    "\n",
    "for i in range(0, len(y) - seq_length):\n",
    "    _x = x[i : i+seq_length]\n",
    "    _y = y[i + seq_length] # 다음 나타날 주가(정답)\n",
    "    if i is 0:\n",
    "        print(_x, \"->\", _y) # 첫번째 행만 출력해 봄\n",
    "    dataX.append(_x) # dataX 리스트에 추가\n",
    "    dataY.append(_y) # dataY 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "personal-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용/테스트용 데이터 생성\n",
    "# 전체 70%를 학습용 데이터로 사용\n",
    "train_size = int(len(dataY) * 0.7)\n",
    "# 나머지(30%)를 테스트용 데이터로 사용\n",
    "test_size = len(dataY) - train_size\n",
    "\n",
    "# 데이터를 잘라 학습용 데이터 생성\n",
    "trainX = np.array(dataX[0:train_size])\n",
    "trainY = np.array(dataY[0:train_size])\n",
    "\n",
    "# 데이터를 잘라 테스트용 데이터 생성\n",
    "testX = np.array(dataX[train_size:len(dataX)])\n",
    "testY = np.array(dataY[train_size:len(dataY)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "automated-boating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Miniconda3\\envs\\mai\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "X:  Tensor(\"Placeholder:0\", shape=(?, 28, 6), dtype=float32)\n",
      "Y:  Tensor(\"Placeholder_1:0\", shape=(?, 1), dtype=float32)\n",
      "targets:  Tensor(\"Placeholder_2:0\", shape=(?, 1), dtype=float32)\n",
      "predictions:  Tensor(\"Placeholder_3:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로우 플레이스홀더 생성\n",
    "# 입력 X, 출력 Y를 생성한다\n",
    "# Note: AttributeError: module 'tensorflow' has no attribute 'placeholder'\n",
    "# https://eclipse360.tistory.com/40\n",
    "# https://min-310.tistory.com/92\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, seq_length, input_data_column_cnt]) \n",
    "\n",
    "\n",
    "print(\"X: \", X)\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "print(\"Y: \", Y)\n",
    "\n",
    "# 검증용 측정지표를 산출하기 위한 targets, predictions를 생성한다\n",
    "targets = tf.placeholder(tf.float32, [None, 1])\n",
    "print(\"targets: \", targets)\n",
    "\n",
    "predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "print(\"predictions: \", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "superior-healthcare",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-9c0c371fdebd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# num_stacked_layers개의 층으로 쌓인 Stacked RNNs 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mstackedRNNs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlstm_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_stacked_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mmulti_cells\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiRNNCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstackedRNNs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_is_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnum_stacked_layers\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlstm_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-9c0c371fdebd>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# num_stacked_layers개의 층으로 쌓인 Stacked RNNs 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mstackedRNNs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlstm_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_stacked_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mmulti_cells\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiRNNCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstackedRNNs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_is_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnum_stacked_layers\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlstm_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-9c0c371fdebd>\u001b[0m in \u001b[0;36mlstm_cell\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# state_is_tuple: True ==> accepted and returned states are 2-tuples of the c_state and m_state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# state_is_tuple: False ==> they are concatenated along the column axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_cell_hidden_dim, \n\u001b[0m\u001b[0;32m     12\u001b[0m                                         forget_bias=forget_bias, state_is_tuple=True, activation=tf.nn.softsign)\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'contrib'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 모델(LSTM 네트워크) 생성\n",
    "def lstm_cell():\n",
    "    # LSTM셀을 생성\n",
    "    # num_units: 각 Cell 출력 크기\n",
    "    # forget_bias:  to the biases of the forget gate \n",
    "    #              (default: 1)  in order to reduce the scale of forgetting in the beginning of the training.\n",
    "    # state_is_tuple: True ==> accepted and returned states are 2-tuples of the c_state and m_state.\n",
    "    # state_is_tuple: False ==> they are concatenated along the column axis.\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_cell_hidden_dim, \n",
    "                                        forget_bias=forget_bias, state_is_tuple=True, activation=tf.nn.softsign)\n",
    "    if keep_prob < 1.0:\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "    return cell\n",
    "\n",
    "# num_stacked_layers개의 층으로 쌓인 Stacked RNNs 생성\n",
    "stackedRNNs = [lstm_cell() for _ in range(num_stacked_layers)]\n",
    "multi_cells = tf.contrib.rnn.MultiRNNCell(stackedRNNs, state_is_tuple=True) if num_stacked_layers > 1 else lstm_cell()\n",
    "\n",
    "# RNN Cell(여기서는 LSTM셀임)들을 연결\n",
    "hypothesis, _states = tf.nn.dynamic_rnn(multi_cells, X, dtype=tf.float32)\n",
    "print(\"hypothesis: \", hypothesis)\n",
    "\n",
    "# [:, -1]를 잘 살펴보자. LSTM RNN의 마지막 (hidden)출력만을 사용했다.\n",
    "# 과거 여러 거래일의 주가를 이용해서 다음날의 주가 1개를 예측하기때문에 MANY-TO-ONE형태이다\n",
    "hypothesis = tf.contrib.layers.fully_connected(hypothesis[:, -1], output_data_column_cnt, activation_fn=tf.identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수로 평균제곱오차를 사용한다\n",
    "loss = tf.reduce_sum(tf.square(hypothesis - Y))\n",
    "# 최적화함수로 AdamOptimizer를 사용한다\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "# optimizer = tf.train.RMSPropOptimizer(learning_rate) # LSTM과 궁합 별로임\n",
    "\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# RMSE(Root Mean Square Error)\n",
    "# 제곱오차의 평균을 구하고 다시 제곱근을 구하면 평균 오차가 나온다\n",
    "# rmse = tf.sqrt(tf.reduce_mean(tf.square(targets-predictions))) # 아래 코드와 같다\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.squared_difference(targets, predictions)))\n",
    "train_error_summary = [] # 학습용 데이터의 오류를 중간 중간 기록한다\n",
    "test_error_summary = []  # 테스트용 데이터의 오류를 중간 중간 기록한다\n",
    "test_predict = ''        # 테스트용데이터로 예측한 결과\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습한다\n",
    "start_time = datetime.datetime.now() # 시작시간을 기록한다\n",
    "print('학습을 시작합니다...')\n",
    "for epoch in range(epoch_num):\n",
    "    _, _loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
    "    if ((epoch+1) % 100 == 0) or (epoch == epoch_num-1): # 100번째마다 또는 마지막 epoch인 경우\n",
    "        # 학습용데이터로 rmse오차를 구한다\n",
    "        train_predict = sess.run(hypothesis, feed_dict={X: trainX})\n",
    "        train_error = sess.run(rmse, feed_dict={targets: trainY, predictions: train_predict})\n",
    "        train_error_summary.append(train_error)\n",
    "\n",
    "        # 테스트용데이터로 rmse오차를 구한다\n",
    "        test_predict = sess.run(hypothesis, feed_dict={X: testX})\n",
    "        test_error = sess.run(rmse, feed_dict={targets: testY, predictions: test_predict})\n",
    "        test_error_summary.append(test_error)\n",
    "        \n",
    "        # 현재 오류를 출력한다\n",
    "        print(\"epoch: {}, train_error(A): {}, test_error(B): {}, B-A: {}\".format(epoch+1, train_error, test_error, test_error-train_error))\n",
    "        \n",
    "end_time = datetime.datetime.now() # 종료시간을 기록한다\n",
    "elapsed_time = end_time - start_time # 경과시간을 구한다\n",
    "print('elapsed_time:',elapsed_time)\n",
    "print('elapsed_time per epoch:',elapsed_time/epoch_num)\n",
    "# 하이퍼파라미터 출력\n",
    "print('input_data_column_cnt:', input_data_column_cnt, end='')\n",
    "print(',output_data_column_cnt:', output_data_column_cnt, end='')\n",
    "\n",
    "print(',seq_length:', seq_length, end='')\n",
    "print(',rnn_cell_hidden_dim:', rnn_cell_hidden_dim, end='')\n",
    "print(',forget_bias:', forget_bias, end='')\n",
    "print(',num_stacked_layers:', num_stacked_layers, end='')\n",
    "print(',keep_prob:', keep_prob, end='')\n",
    "\n",
    "print(',epoch_num:', epoch_num, end='')\n",
    "print(',learning_rate:', learning_rate, end='')\n",
    "\n",
    "print(',train_error:', train_error_summary[-1], end='')\n",
    "print(',test_error:', test_error_summary[-1], end='')\n",
    "print(',min_test_error:', np.min(test_error_summary))\n",
    "\n",
    "# 결과 그래프 출력\n",
    "plt.figure(1)\n",
    "plt.plot(train_error_summary, 'gold')\n",
    "plt.plot(test_error_summary, 'b')\n",
    "plt.xlabel('Epoch(x100)')\n",
    "plt.ylabel('Root Mean Square Error')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(testY, 'r')\n",
    "plt.plot(test_predict, 'b')\n",
    "plt.xlabel('Time Period')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.show()\n",
    "# sequence length만큼의 가장 최근 데이터를 슬라이싱한다\n",
    "recent_data = np.array([x[len(x)-seq_length : ]])\n",
    "print(\"recent_data.shape:\", recent_data.shape)\n",
    "print(\"recent_data:\", recent_data)\n",
    "\n",
    "# 내일 종가를 예측해본다\n",
    "test_predict = sess.run(hypothesis, feed_dict={X: recent_data})\n",
    "\n",
    "print(\"test_predict\", test_predict[0])\n",
    "test_predict = reverse_min_max_scaling(price,test_predict) # 금액데이터 역정규화한다\n",
    "print(\"Tomorrow's stock price\", test_predict[0]) # 예측한 주가를 출력한다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAI",
   "language": "python",
   "name": "mai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
